version: 2.1

orbs:
  aws-ecr: circleci/aws-ecr@7.0.0

aws_docker_image: &aws_docker_image
  docker:
    - image: amazon/aws-cli

python_docker_image: &python_docker_image
  docker:
    - image: python:3.7.3-stretch

commands:
  destroy-environment:
    description: Destroy vpc and eks cloudformation stacks given a workflow ID.    
    steps:
      - run:
          name: Destroy environment
          when: on_fail
          command: |
              aws cloudformation delete-stack --stack-name eksctl-${ENV_NAME}-cluster-addon-iamserviceaccount-kube-system-aws-load-balancer-controller 
              aws cloudformation wait stack-delete-complete --stack-name eksctl-${ENV_NAME}-nodegroup-${ENV_NAME}-worker
              aws cloudformation delete-stack --stack-name eksctl-${ENV_NAME}-cluster-cluster              
              # Detach and delete policy
              aws iam detach-role-policy --policy-arn arn:aws:iam::246528985509:policy/AWSLoadBalancerControllerIAMPolicy --role-name AmazonEKSLoadBalancerControllerRole
              aws iam delete-policy --policy-arn arn:aws:iam::246528985509:policy/AWSLoadBalancerControllerIAMPolicy
              aws iam delete-role --role-name AmazonEKSLoadBalancerControllerRole        

jobs:

    build-test-lint:
      <<: *python_docker_image
      working_directory: ~/repo
      steps:
        - checkout
        - restore_cache:
            keys:
              - v1-dependencies-{{ checksum "./app/requirements.txt" }}
              # fallback to using the latest cache if no exact match is found
              - v1-dependencies-
        - run:
            name: set up python
            command: |
                cd ./app
                make setup
        - run:
            name: install dependencies
            command: |
                cd ./app
                make install
        - save_cache:
            paths:
                - ./.devops
            key: v1-dependencies-{{ checksum "./app/requirements.txt" }}
        - run:
            name: run test
            command: |
                cd ./app
                make test
        - run:
            name: run lint
            command: |
              cd ./app
              source .devops/bin/activate
              make lint
  
    deploy-aws-eks:
      <<: *aws_docker_image
      steps:
        - checkout
        - run:  
            name: Install tar and gzip
            command: |
              yum install -y tar gzip
        - run:
            name: install eksctl
            command: |
                curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
                mv /tmp/eksctl /usr/local/bin
        - run:
            name: install kubectl
            command: |
              curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" &&\
              curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256" &&\
              echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check &&
              chmod +x kubectl
              mv ./kubectl /usr/local/bin/kubectl
              kubectl version --short --client

        - run:
            name: create eks cluster and worker nodes
            command: |
              cd .circleci/scripts
              chmod +x deploy-cluster.sh
              ./deploy-cluster.sh ${ENV_NAME}
            no_output_timeout: 60m
        # - run:
        #     name: install openSSL
        #     command: yum install -y openssl
        # - run:
        #     name: install helm
        #     command: |
        #       curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 > get_helm.sh
        #       chmod 700 get_helm.sh
        #       ./get_helm.sh
        # - run: 
        #     name: create IAM OIDC
        #     command: eksctl utils associate-iam-oidc-provider --region us-east-1 --cluster ${ENV_NAME}-cluster --approve
        # - run:
        #     name: create load balancer policy
        #     command: |           
        #       cd .circleci/scripts
        #       chmod +x create-alb-policy.sh
        #       ./create-alb-policy.sh ${ENV_NAME} AmazonEKSLoadBalancerControllerRole ${AWS_ACCOUNT}
        # - run:
        #     name: setup ALB
        #     command: |
        #       cd .circleci/scripts
        #       chmod +x deploy-alb.sh
        #       export VPC=$(aws ec2 describe-vpcs --region us-east-1 --filters "Name=tag-value,Values=eksctl-${ENV_NAME}-cluster-cluster/VPC" --query 'Vpcs[*].VpcId' --output text)
              
        #       ./deploy-alb.sh ${ENV_NAME} ${AWS_ACCOUNT} $VPC
        - destroy-environment

    deploy-service-in-eks:
      <<: *aws_docker_image
      steps:
        - checkout
        - run:  
            name: Install tar and gzip
            command: |
              yum install -y tar gzip
        - run:
            name: install kubectl
            command: |
              curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" &&\
              curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256" &&\
              echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check &&
              chmod +x kubectl
              mv ./kubectl /usr/local/bin/kubectl
              kubectl version --short --client
        - run:
            name: deploy pods
            command: |
              aws eks update-kubeconfig --name $ENV_NAME-cluster --region us-east-1
              # Assuming the Kubernetes cluster is ready
              kubectl get nodes
              # Deploy an App from the Dockerhub to the Kubernetes Cluster
              kubectl create deploy uda-capstone-project --image=${ECR_URI}/uda-capstone-project:${CIRCLE_WORKFLOW_ID:0:7}
              # See the status
              kubectl get deploy,rs,svc,pods
              # Port forward 
              kubectl port-forward pod/uda-capstone-project-84857d9565-2598m --address 0.0.0.0 5000:5000
workflows:
  deploy-application:
    jobs:
      # - build-test-lint:
      #     filters:
      #       branches:
      #         only: [main]
      - deploy-aws-eks:
          filters:
            branches:
              only: [deploy-infrastructure]
      - aws-ecr/build-and-push-image:
          # requires: [build-test-lint]
          filters:
            branches:
              only: [main]
          account-url: ECR_URI
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          region: AWS_DEFAULT_REGION
          create-repo: true
          dockerfile: Dockerfile
          path: ./app
          repo: uda-capstone-project
          tag: ${CIRCLE_WORKFLOW_ID:0:7}
      - deploy-service-in-eks:
          requires: [aws-ecr/build-and-push-image]
          filters:
            branches:
              only: [main]