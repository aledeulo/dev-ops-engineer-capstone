version: 2.1

orbs:
  aws-ecr: circleci/aws-ecr@7.0.0
  aws-eks: circleci/aws-eks@2.2.0
  kubernetes: circleci/kubernetes@1.3

aws_docker_image: &aws_docker_image
  docker:
    - image: amazon/aws-cli

python_docker_image: &python_docker_image
  docker:
    - image: python:3.7.3-stretch

python_cluster_docker_image: &python_cluster_docker_image
  docker:
    - image: cimg/python:3.10

commands:
  install_aws_cli:
    description: Configure aws cli to deploy resources
    steps:
      - run:
          name: install aws cli
          command: |
            pip install awscli
            aws configure set aws_access_key_id ${AWS_ACCESS_KEY_ID}
            aws configure set aws_secret_access_key ${AWS_SECRET_ACCESS_KEY}
            aws configure set region ${AWS_DEFAULT_REGION}   

jobs:

    build-test-lint:
      <<: *python_docker_image
      working_directory: ~/repo
      steps:
        - checkout
        - restore_cache:
            keys:
              - v1-dependencies-{{ checksum "./app/requirements.txt" }}
              # fallback to using the latest cache if no exact match is found
              - v1-dependencies-
        - run:
            name: set up python
            command: |
                cd ./app
                make setup
        - run:
            name: install dependencies
            command: |
                cd ./app
                make install
        - save_cache:
            paths:
                - ./.devops
            key: v1-dependencies-{{ checksum "./app/requirements.txt" }}
        - run:
            name: run test
            command: |
                cd ./app
                make test
        - run:
            name: run lint
            command: |
              cd ./app
              source .devops/bin/activate
              make lint
  
    deploy-aws-eks:
      <<: *python_cluster_docker_image
      steps:
        - checkout
        - run:
            name: check if the cluster exist
            command: |

              export VALIDATE=$(aws eks describe-cluster --name ${ENV_NAME}-cluster --query 'cluster.name')
              echo "$VALIDATE" > ~/validate
              if cat ~/validate | grep "${ENV_NAME}-cluster"
              then
                  echo "Cluster ${ENV_NAME}-cluster already exist. Skipping job"
                  circleci-agent step halt
                  exit 0
              else
                  echo "Attempting to create the cluster $ENV_NAME-cluster"
              fi
        - aws-eks/create-cluster:
            cluster-name: ${ENV_NAME}-cluster 
            aws-region: ${AWS_DEFAULT_REGION}
            nodegroup-name: ${ENV_NAME}-workers
            node-type: t2.micro
            nodes-min: 2
            nodes-max: 3
            ssh-public-key: DEFAULT_EKS_US_EAST_2_Key

    prepare-eks-deployment:
      <<: *python_cluster_docker_image
      steps:
        - checkout
        - aws-eks/update-kubeconfig-with-authenticator:
            cluster-name: ${ENV_NAME}-cluster
            install-kubectl: true
        - kubernetes/create-or-update-resource:
            get-rollout-status: true
            resource-file-path: .circleci/files/deployment.yml
            resource-name: deployment/uda-capstone-project
            show-kubectl-command: true
        - run:
            name: check-deployment status before delete old deployment
            command:  kubectl get svc uda-capstone-project

workflows:
  deploy-application:
    jobs:
      - build-test-lint:
          filters:
            branches:
              only: [main]
      - deploy-aws-eks:
          filters:
            branches:
              only: [main, deploy-infrastructure]
      - aws-ecr/build-and-push-image:
          requires: [build-test-lint]
          filters:
            branches:
              only: [main]
          account-url: ECR_URI
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          region: AWS_DEFAULT_REGION
          create-repo: true
          dockerfile: Dockerfile
          path: ./app
          repo: uda-capstone-project
          tag: latest
      - prepare-eks-deployment:
          requires: [aws-ecr/build-and-push-image, deploy-aws-eks]
          filters:
            branches:
              only: [main]
      - aws-eks/update-container-image:
          requires: [prepare-eks-deployment]
          filters:
            branches:
              only: [main]
          cluster-name: ${ENV_NAME}-cluster
          container-image-updates: 'uda-capstone-project=uda-capstone-project:latest'
          post-steps:
            - kubernetes/delete-resource:
                resource-names: uda-capstone-project
                resource-types: deployment
                wait: true